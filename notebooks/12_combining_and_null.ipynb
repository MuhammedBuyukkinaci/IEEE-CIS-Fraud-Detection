{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "import missingno as msno\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from tqdm import tqdm_notebook\n",
    "np.set_printoptions(suppress=True)\n",
    "from sklearn import preprocessing\n",
    "from tqdm import tqdm\n",
    "import decimal\n",
    "from itertools import combinations\n",
    "from random import shuffle\n",
    "from time import sleep\n",
    "tqdm.pandas()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import gc\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split, KFold, GroupKFold\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score\n",
    "plt.style.use('ggplot')\n",
    "np.set_printoptions(suppress=True)\n",
    "import random\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Always seed the randomness of this universe\n",
    "def seed_everything(seed=51):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(seed=51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train finished\n",
      "CPU times: user 50.3 s, sys: 4.13 s, total: 54.5 s\n",
      "Wall time: 54.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_csv('../input/train4.csv')\n",
    "print(\"train finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test finished\n",
      "CPU times: user 42.2 s, sys: 1.95 s, total: 44.1 s\n",
      "Wall time: 44.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test = pd.read_csv('../input/test4.csv')\n",
    "print(\"test finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(590540, 915) (506691, 914) (506691, 2)\n"
     ]
    }
   ],
   "source": [
    "#sample_submission\n",
    "sample_submission = pd.read_csv('../input/sample_submission.csv')\n",
    "print(train.shape,test.shape,sample_submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(590540, 915) (506691, 914)\n"
     ]
    }
   ],
   "source": [
    "#y = train['isFraud']\n",
    "#del train['isFraud']\n",
    "gc.collect()\n",
    "print(train.shape,test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"importances = pd.read_csv('./importances/importances1.csv')\\nprint(importances.shape)\\nimportances = importances[:700]\\nfeatures = [x for x in list(importances['index']) if x not in ['TransactionID','TransactionDT']]\\ntrain = train[features]\\ntest = test[features]\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"importances = pd.read_csv('./importances/importances1.csv')\n",
    "print(importances.shape)\n",
    "importances = importances[:700]\n",
    "features = [x for x in list(importances['index']) if x not in ['TransactionID','TransactionDT']]\n",
    "train = train[features]\n",
    "test = test[features]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape,test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['ProductCD','card1','card2','card3','card4','card5','dist1','dist2','P_emaildomain','R_emaildomain','DeviceInfo']\n",
    "print(len(cat_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[cat_cols].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_less_common(x):\n",
    "    if x not in shared_list:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tuple_ in list(combinations(cat_cols,2)):\n",
    "    f1 = tuple_[0]\n",
    "    f2 = tuple_[1]\n",
    "    column_name = f1 + '_' + f2\n",
    "    \n",
    "    train[column_name] = train[f1].apply(str) + '_' + train[f2].apply(str)\n",
    "    test[column_name] = test[f1].apply(str) +  '_' +test[f2].apply(str)\n",
    "    \n",
    "    shared_list = list( set(train[column_name]).intersection(set(test[column_name] )) )\n",
    "    shared = len(shared_list)\n",
    "    \n",
    "    only_train = train[column_name].nunique() - len(shared_list)\n",
    "    only_test = test[column_name].nunique() - len(shared_list)\n",
    "    print(column_name)\n",
    "    train[column_name] = train[column_name].apply(convert_less_common)\n",
    "    test[column_name] = test[column_name].apply(convert_less_common)\n",
    "    \n",
    "    print( column_name,round(shared/(shared + only_train),3) )\n",
    "    print( column_name,round(shared/(shared + only_test),3) )\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    del shared_list,shared,only_train,only_test\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tuple_ in tqdm(list(combinations(cat_cols,2))):\n",
    "    f1 = tuple_[0]\n",
    "    f2 = tuple_[1]\n",
    "    column_name = f1 + '_' + f2\n",
    "    train[column_name + '_isnull'] = train[column_name].isnull()*1\n",
    "    test[column_name + '_isnull'] = test[column_name].isnull()*1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(combinations(cat_cols,2))[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape,test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tuple_ in tqdm(list(combinations(cat_cols,2))):\n",
    "    f1 = tuple_[0]\n",
    "    f2 = tuple_[1]\n",
    "    column_name = f1 + '_' + f2\n",
    "    train[column_name] = train[column_name].fillna('999999')\n",
    "    test[column_name] = test[column_name].fillna('999999')\n",
    "    le = LabelEncoder()\n",
    "    le.fit(list(train[column_name]) + list(test[column_name]))\n",
    "    train[column_name] = le.transform(train[column_name])\n",
    "    test[column_name] = le.transform(test[column_name])\n",
    "print(train.shape,test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[column_name].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train.to_csv('../input/train5.csv',index=False)\n",
    "test.to_csv('../input/test5.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['isFraud']\n",
    "del train['isFraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Model params\n",
    "lgb_params = {\n",
    "                    'objective':'binary',\n",
    "                    'boosting_type':'gbdt',\n",
    "                    'metric':'auc',\n",
    "                    'n_jobs':-1,\n",
    "                    'learning_rate':0.02,\n",
    "                    'num_leaves': 2**8,\n",
    "                    'max_depth':12,\n",
    "                    'tree_learner':'serial',\n",
    "                    'colsample_bytree': 0.5,\n",
    "                    'subsample_freq':1,\n",
    "                    'subsample':0.7,\n",
    "                    'n_estimators':2000,\n",
    "                    'max_bin':255,\n",
    "                    'verbose':-1,\n",
    "                    'seed': 51,\n",
    "                    'early_stopping_rounds':100, \n",
    "                } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train = reduce_mem_usage(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test = reduce_mem_usage(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:116: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:121: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.956543\tvalid_1's auc: 0.891993\n",
      "[200]\ttraining's auc: 0.980104\tvalid_1's auc: 0.907963\n",
      "[300]\ttraining's auc: 0.9881\tvalid_1's auc: 0.915931\n",
      "[400]\ttraining's auc: 0.992258\tvalid_1's auc: 0.920552\n",
      "[500]\ttraining's auc: 0.994866\tvalid_1's auc: 0.923222\n",
      "[600]\ttraining's auc: 0.99664\tvalid_1's auc: 0.924537\n",
      "[700]\ttraining's auc: 0.997723\tvalid_1's auc: 0.925969\n",
      "[800]\ttraining's auc: 0.998508\tvalid_1's auc: 0.926367\n",
      "[900]\ttraining's auc: 0.99906\tvalid_1's auc: 0.926812\n",
      "[1000]\ttraining's auc: 0.999438\tvalid_1's auc: 0.927076\n",
      "[1100]\ttraining's auc: 0.999654\tvalid_1's auc: 0.926817\n",
      "Early stopping, best iteration is:\n",
      "[1007]\ttraining's auc: 0.999446\tvalid_1's auc: 0.927162\n",
      "Fold 1 ROC AUC Score 0.9271622042838722\n",
      "\n",
      "Fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:116: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:121: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.954117\tvalid_1's auc: 0.910675\n",
      "[200]\ttraining's auc: 0.97988\tvalid_1's auc: 0.92624\n",
      "[300]\ttraining's auc: 0.989143\tvalid_1's auc: 0.932175\n",
      "[400]\ttraining's auc: 0.993131\tvalid_1's auc: 0.9349\n",
      "[500]\ttraining's auc: 0.995543\tvalid_1's auc: 0.937144\n",
      "[600]\ttraining's auc: 0.997114\tvalid_1's auc: 0.938512\n",
      "[700]\ttraining's auc: 0.998136\tvalid_1's auc: 0.939271\n",
      "[800]\ttraining's auc: 0.998819\tvalid_1's auc: 0.940008\n",
      "[900]\ttraining's auc: 0.999296\tvalid_1's auc: 0.940718\n",
      "[1000]\ttraining's auc: 0.999599\tvalid_1's auc: 0.941202\n",
      "[1100]\ttraining's auc: 0.999779\tvalid_1's auc: 0.941699\n",
      "[1200]\ttraining's auc: 0.99988\tvalid_1's auc: 0.941678\n",
      "Early stopping, best iteration is:\n",
      "[1122]\ttraining's auc: 0.999815\tvalid_1's auc: 0.941847\n",
      "Fold 2 ROC AUC Score 0.9418471644497299\n",
      "\n",
      "Fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:116: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:121: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.9572\tvalid_1's auc: 0.911297\n",
      "[200]\ttraining's auc: 0.981659\tvalid_1's auc: 0.925559\n",
      "[300]\ttraining's auc: 0.990125\tvalid_1's auc: 0.930725\n",
      "[400]\ttraining's auc: 0.993945\tvalid_1's auc: 0.93244\n",
      "[500]\ttraining's auc: 0.995915\tvalid_1's auc: 0.933198\n",
      "[600]\ttraining's auc: 0.997255\tvalid_1's auc: 0.933151\n",
      "[700]\ttraining's auc: 0.998221\tvalid_1's auc: 0.933681\n",
      "[800]\ttraining's auc: 0.998966\tvalid_1's auc: 0.933867\n",
      "[900]\ttraining's auc: 0.999373\tvalid_1's auc: 0.933848\n",
      "Early stopping, best iteration is:\n",
      "[886]\ttraining's auc: 0.999333\tvalid_1's auc: 0.933995\n",
      "Fold 3 ROC AUC Score 0.9339950429070237\n",
      "\n",
      "Fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:116: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:121: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.953622\tvalid_1's auc: 0.925665\n",
      "[200]\ttraining's auc: 0.980517\tvalid_1's auc: 0.94139\n",
      "[300]\ttraining's auc: 0.989093\tvalid_1's auc: 0.947232\n",
      "[400]\ttraining's auc: 0.993245\tvalid_1's auc: 0.949728\n",
      "[500]\ttraining's auc: 0.995704\tvalid_1's auc: 0.95097\n",
      "[600]\ttraining's auc: 0.997336\tvalid_1's auc: 0.951356\n",
      "[700]\ttraining's auc: 0.998304\tvalid_1's auc: 0.95142\n",
      "Early stopping, best iteration is:\n",
      "[683]\ttraining's auc: 0.998188\tvalid_1's auc: 0.951504\n",
      "Fold 4 ROC AUC Score 0.9515041433324347\n",
      "\n",
      "Fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:116: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:121: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.954619\tvalid_1's auc: 0.902239\n",
      "[200]\ttraining's auc: 0.980536\tvalid_1's auc: 0.919845\n",
      "[300]\ttraining's auc: 0.989476\tvalid_1's auc: 0.925148\n",
      "[400]\ttraining's auc: 0.993589\tvalid_1's auc: 0.928\n",
      "[500]\ttraining's auc: 0.995881\tvalid_1's auc: 0.929364\n",
      "[600]\ttraining's auc: 0.997255\tvalid_1's auc: 0.929772\n",
      "[700]\ttraining's auc: 0.998254\tvalid_1's auc: 0.929689\n",
      "Early stopping, best iteration is:\n",
      "[606]\ttraining's auc: 0.997338\tvalid_1's auc: 0.929891\n",
      "Fold 5 ROC AUC Score 0.9298906329357063\n",
      "\n",
      "Average ROC AUC Score 0.9368798375817533 [STD:0.008833437311879187]\n"
     ]
    }
   ],
   "source": [
    "N = 5\n",
    "kf = KFold(n_splits=N)\n",
    "\n",
    "importance = pd.DataFrame(np.zeros((train.shape[1], N)), columns=['Fold_{}'.format(i) for i in range(1, N + 1)], index=train.columns)\n",
    "scores = []\n",
    "y_pred = np.zeros(test.shape[0])\n",
    "oof = np.zeros(train.shape[0])\n",
    "\n",
    "for fold, (trn_idx, val_idx) in enumerate(kf.split(train, y), 1):\n",
    "    print('Fold {}'.format(fold))\n",
    "          \n",
    "    trn_data = lgb.Dataset(train.iloc[trn_idx, :].values, label=y.iloc[trn_idx].values)\n",
    "    val_data = lgb.Dataset(train.iloc[val_idx, :].values, label=y.iloc[val_idx].values)   \n",
    "    \n",
    "    clf = lgb.train(lgb_params, trn_data ,valid_sets=[trn_data, val_data], verbose_eval=100)\n",
    "\n",
    "    predictions = clf.predict(train.iloc[val_idx, :].values) \n",
    "    importance.iloc[:, fold - 1] = clf.feature_importance()\n",
    "    oof[val_idx] = predictions\n",
    "\n",
    "    score = roc_auc_score(y.iloc[val_idx].values, predictions)\n",
    "    scores.append(score)\n",
    "    print('Fold {} ROC AUC Score {}\\n'.format(fold, score))\n",
    "\n",
    "    y_pred += clf.predict(test) / N\n",
    "    \n",
    "    del trn_data, val_data, predictions\n",
    "    gc.collect()\n",
    "    \n",
    "print('Average ROC AUC Score {} [STD:{}]'.format(np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9354840326091465\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y,oof))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance['avg'] = importance.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = importance.sort_values(by='avg',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = importance.reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Fold_1</th>\n",
       "      <th>Fold_2</th>\n",
       "      <th>Fold_3</th>\n",
       "      <th>Fold_4</th>\n",
       "      <th>Fold_5</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TransactionID</td>\n",
       "      <td>6898</td>\n",
       "      <td>7619</td>\n",
       "      <td>6205</td>\n",
       "      <td>4471</td>\n",
       "      <td>3755</td>\n",
       "      <td>5789.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TransactionAmt</td>\n",
       "      <td>6430</td>\n",
       "      <td>7404</td>\n",
       "      <td>5594</td>\n",
       "      <td>4257</td>\n",
       "      <td>3924</td>\n",
       "      <td>5521.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>addr1</td>\n",
       "      <td>4686</td>\n",
       "      <td>5689</td>\n",
       "      <td>4052</td>\n",
       "      <td>3092</td>\n",
       "      <td>2773</td>\n",
       "      <td>4058.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>card1</td>\n",
       "      <td>4798</td>\n",
       "      <td>5197</td>\n",
       "      <td>4259</td>\n",
       "      <td>3056</td>\n",
       "      <td>2714</td>\n",
       "      <td>4004.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>day</td>\n",
       "      <td>3846</td>\n",
       "      <td>4515</td>\n",
       "      <td>3256</td>\n",
       "      <td>2442</td>\n",
       "      <td>2042</td>\n",
       "      <td>3220.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            index  Fold_1  Fold_2  Fold_3  Fold_4  Fold_5     avg\n",
       "0   TransactionID    6898    7619    6205    4471    3755  5789.6\n",
       "1  TransactionAmt    6430    7404    5594    4257    3924  5521.8\n",
       "2           addr1    4686    5689    4052    3092    2773  4058.4\n",
       "3           card1    4798    5197    4259    3056    2714  4004.8\n",
       "4             day    3846    4515    3256    2442    2042  3220.2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance.to_csv('../importances/importances7.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3663549</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3663550</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3663551</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3663552</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3663553</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  isFraud\n",
       "0        3663549      0.5\n",
       "1        3663550      0.5\n",
       "2        3663551      0.5\n",
       "3        3663552      0.5\n",
       "4        3663553      0.5"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['isFraud'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3663549</td>\n",
       "      <td>0.001333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3663550</td>\n",
       "      <td>0.001398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3663551</td>\n",
       "      <td>0.002326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3663552</td>\n",
       "      <td>0.001364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3663553</td>\n",
       "      <td>0.001672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID   isFraud\n",
       "0        3663549  0.001333\n",
       "1        3663550  0.001398\n",
       "2        3663551  0.002326\n",
       "3        3663552  0.001364\n",
       "4        3663553  0.001672"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv('../predictions/pred7.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.1.1)\n",
      "100%|███████████████████████████████████████| 14.1M/14.1M [00:33<00:00, 444kB/s]\n",
      "Successfully submitted to IEEE-CIS Fraud Detection"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c ieee-fraud-detection -f ../predictions/pred7.csv -m \"pred7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
