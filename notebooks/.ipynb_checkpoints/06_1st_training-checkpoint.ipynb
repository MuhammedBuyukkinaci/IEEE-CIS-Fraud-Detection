{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "import missingno as msno\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from tqdm import tqdm_notebook\n",
    "np.set_printoptions(suppress=True)\n",
    "from sklearn import preprocessing\n",
    "from tqdm import tqdm\n",
    "import decimal\n",
    "from random import shuffle\n",
    "from time import sleep\n",
    "tqdm.pandas()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import gc\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split, KFold, GroupKFold\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score\n",
    "plt.style.use('ggplot')\n",
    "np.set_printoptions(suppress=True)\n",
    "import random\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Always seed the randomness of this universe\n",
    "def seed_everything(seed=51):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(seed=51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train finished\n",
      "CPU times: user 42.2 s, sys: 3.98 s, total: 46.2 s\n",
      "Wall time: 46.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_csv('../input/train4.csv')\n",
    "print(\"train finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test finished\n",
      "CPU times: user 36 s, sys: 2.17 s, total: 38.2 s\n",
      "Wall time: 38.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test = pd.read_csv('../input/test4.csv')\n",
    "print(\"test finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(590540, 805) (506691, 804) (506691, 2)\n"
     ]
    }
   ],
   "source": [
    "#sample_submission\n",
    "sample_submission = pd.read_csv('../input/sample_submission.csv')\n",
    "print(train.shape,test.shape,sample_submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(590540, 804) (506691, 804)\n"
     ]
    }
   ],
   "source": [
    "y = train['isFraud']\n",
    "del train['isFraud']\n",
    "gc.collect()\n",
    "print(train.shape,test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Model params\n",
    "lgb_params = {\n",
    "                    'objective':'binary',\n",
    "                    'boosting_type':'gbdt',\n",
    "                    'metric':'auc',\n",
    "                    'n_jobs':-1,\n",
    "                    'learning_rate':0.02,\n",
    "                    'num_leaves': 2**8,\n",
    "                    'max_depth':12,\n",
    "                    'tree_learner':'serial',\n",
    "                    'colsample_bytree': 0.5,\n",
    "                    'subsample_freq':1,\n",
    "                    'subsample':0.7,\n",
    "                    'n_estimators':2000,\n",
    "                    'max_bin':255,\n",
    "                    'verbose':-1,\n",
    "                    'seed': 51,\n",
    "                    'early_stopping_rounds':100, \n",
    "                } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:116: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:121: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.950458\tvalid_1's auc: 0.887526\n",
      "[200]\ttraining's auc: 0.975745\tvalid_1's auc: 0.904535\n",
      "[300]\ttraining's auc: 0.985176\tvalid_1's auc: 0.913192\n",
      "[400]\ttraining's auc: 0.989999\tvalid_1's auc: 0.918221\n",
      "[500]\ttraining's auc: 0.992988\tvalid_1's auc: 0.920958\n",
      "[600]\ttraining's auc: 0.99485\tvalid_1's auc: 0.922593\n",
      "[700]\ttraining's auc: 0.996325\tvalid_1's auc: 0.924179\n",
      "[800]\ttraining's auc: 0.997386\tvalid_1's auc: 0.92473\n",
      "[900]\ttraining's auc: 0.998212\tvalid_1's auc: 0.925457\n",
      "[1000]\ttraining's auc: 0.998739\tvalid_1's auc: 0.925598\n",
      "[1100]\ttraining's auc: 0.999183\tvalid_1's auc: 0.925718\n",
      "[1200]\ttraining's auc: 0.999481\tvalid_1's auc: 0.925892\n",
      "[1300]\ttraining's auc: 0.999688\tvalid_1's auc: 0.926334\n",
      "[1400]\ttraining's auc: 0.999803\tvalid_1's auc: 0.926297\n",
      "Early stopping, best iteration is:\n",
      "[1318]\ttraining's auc: 0.999712\tvalid_1's auc: 0.926385\n",
      "Fold 1 ROC AUC Score 0.9263848864263222\n",
      "\n",
      "Fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:116: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:121: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.948801\tvalid_1's auc: 0.906116\n",
      "[200]\ttraining's auc: 0.975917\tvalid_1's auc: 0.922448\n",
      "[300]\ttraining's auc: 0.985725\tvalid_1's auc: 0.92844\n",
      "[400]\ttraining's auc: 0.990523\tvalid_1's auc: 0.931632\n",
      "[500]\ttraining's auc: 0.993323\tvalid_1's auc: 0.933242\n",
      "[600]\ttraining's auc: 0.995322\tvalid_1's auc: 0.93484\n",
      "[700]\ttraining's auc: 0.996734\tvalid_1's auc: 0.935548\n",
      "[800]\ttraining's auc: 0.99785\tvalid_1's auc: 0.936334\n",
      "[900]\ttraining's auc: 0.998668\tvalid_1's auc: 0.937109\n",
      "[1000]\ttraining's auc: 0.999194\tvalid_1's auc: 0.937316\n",
      "[1100]\ttraining's auc: 0.999492\tvalid_1's auc: 0.938371\n",
      "Early stopping, best iteration is:\n",
      "[1034]\ttraining's auc: 0.999319\tvalid_1's auc: 0.938565\n",
      "Fold 2 ROC AUC Score 0.9385645183143027\n",
      "\n",
      "Fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:116: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:121: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.952674\tvalid_1's auc: 0.908239\n",
      "[200]\ttraining's auc: 0.977618\tvalid_1's auc: 0.923043\n",
      "[300]\ttraining's auc: 0.986504\tvalid_1's auc: 0.927743\n",
      "[400]\ttraining's auc: 0.990942\tvalid_1's auc: 0.929739\n",
      "[500]\ttraining's auc: 0.993874\tvalid_1's auc: 0.930869\n",
      "[600]\ttraining's auc: 0.995605\tvalid_1's auc: 0.931257\n",
      "[700]\ttraining's auc: 0.996908\tvalid_1's auc: 0.931687\n",
      "[800]\ttraining's auc: 0.998001\tvalid_1's auc: 0.932079\n",
      "[900]\ttraining's auc: 0.998639\tvalid_1's auc: 0.931989\n",
      "Early stopping, best iteration is:\n",
      "[802]\ttraining's auc: 0.998038\tvalid_1's auc: 0.932129\n",
      "Fold 3 ROC AUC Score 0.9321290837050848\n",
      "\n",
      "Fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:116: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:121: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.948737\tvalid_1's auc: 0.922385\n",
      "[200]\ttraining's auc: 0.976077\tvalid_1's auc: 0.938569\n",
      "[300]\ttraining's auc: 0.986002\tvalid_1's auc: 0.944167\n",
      "[400]\ttraining's auc: 0.990576\tvalid_1's auc: 0.94683\n",
      "[500]\ttraining's auc: 0.993794\tvalid_1's auc: 0.948428\n",
      "[600]\ttraining's auc: 0.99569\tvalid_1's auc: 0.949585\n",
      "[700]\ttraining's auc: 0.997129\tvalid_1's auc: 0.950172\n",
      "[800]\ttraining's auc: 0.998085\tvalid_1's auc: 0.950393\n",
      "[900]\ttraining's auc: 0.998672\tvalid_1's auc: 0.950279\n",
      "Early stopping, best iteration is:\n",
      "[853]\ttraining's auc: 0.998431\tvalid_1's auc: 0.950496\n",
      "Fold 4 ROC AUC Score 0.9504963121428377\n",
      "\n",
      "Fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:116: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:121: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.952064\tvalid_1's auc: 0.897683\n",
      "[200]\ttraining's auc: 0.976663\tvalid_1's auc: 0.913653\n",
      "[300]\ttraining's auc: 0.986645\tvalid_1's auc: 0.919317\n",
      "[400]\ttraining's auc: 0.991359\tvalid_1's auc: 0.921773\n",
      "[500]\ttraining's auc: 0.994085\tvalid_1's auc: 0.922814\n",
      "[600]\ttraining's auc: 0.995915\tvalid_1's auc: 0.92382\n",
      "[700]\ttraining's auc: 0.997115\tvalid_1's auc: 0.923988\n",
      "[800]\ttraining's auc: 0.998112\tvalid_1's auc: 0.924821\n",
      "[900]\ttraining's auc: 0.998786\tvalid_1's auc: 0.924902\n",
      "Early stopping, best iteration is:\n",
      "[882]\ttraining's auc: 0.998675\tvalid_1's auc: 0.925337\n",
      "Fold 5 ROC AUC Score 0.925336847212859\n",
      "\n",
      "Average ROC AUC Score 0.9345823295602813 [STD:0.009249952452932834]\n",
      "CPU times: user 4h 15min 45s, sys: 50.5 s, total: 4h 16min 35s\n",
      "Wall time: 34min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "N = 5\n",
    "kf = KFold(n_splits=N)\n",
    "\n",
    "importance = pd.DataFrame(np.zeros((train.shape[1], N)), columns=['Fold_{}'.format(i) for i in range(1, N + 1)], index=train.columns)\n",
    "scores = []\n",
    "y_pred = np.zeros(test.shape[0])\n",
    "oof = np.zeros(train.shape[0])\n",
    "\n",
    "for fold, (trn_idx, val_idx) in enumerate(kf.split(train, y), 1):\n",
    "    print('Fold {}'.format(fold))\n",
    "          \n",
    "    trn_data = lgb.Dataset(train.iloc[trn_idx, :].values, label=y.iloc[trn_idx].values)\n",
    "    val_data = lgb.Dataset(train.iloc[val_idx, :].values, label=y.iloc[val_idx].values)   \n",
    "    \n",
    "    clf = lgb.train(lgb_params, trn_data ,valid_sets=[trn_data, val_data], verbose_eval=100)\n",
    "\n",
    "    predictions = clf.predict(train.iloc[val_idx, :].values) \n",
    "    importance.iloc[:, fold - 1] = clf.feature_importance()\n",
    "    oof[val_idx] = predictions\n",
    "\n",
    "    score = roc_auc_score(y.iloc[val_idx].values, predictions)\n",
    "    scores.append(score)\n",
    "    print('Fold {} ROC AUC Score {}\\n'.format(fold, score))\n",
    "\n",
    "    y_pred += clf.predict(test) / N\n",
    "    \n",
    "    del trn_data, val_data, predictions\n",
    "    gc.collect()\n",
    "    \n",
    "print('Average ROC AUC Score {} [STD:{}]'.format(np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance['avg'] = importance.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = importance.sort_values(by='avg',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = importance.reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Fold_1</th>\n",
       "      <th>Fold_2</th>\n",
       "      <th>Fold_3</th>\n",
       "      <th>Fold_4</th>\n",
       "      <th>Fold_5</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>card1</td>\n",
       "      <td>12171</td>\n",
       "      <td>9377</td>\n",
       "      <td>7007</td>\n",
       "      <td>7353</td>\n",
       "      <td>8683</td>\n",
       "      <td>8918.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TransactionID</td>\n",
       "      <td>11609</td>\n",
       "      <td>9044</td>\n",
       "      <td>6608</td>\n",
       "      <td>6961</td>\n",
       "      <td>7552</td>\n",
       "      <td>8354.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TransactionAmt</td>\n",
       "      <td>11495</td>\n",
       "      <td>8869</td>\n",
       "      <td>6180</td>\n",
       "      <td>7030</td>\n",
       "      <td>7031</td>\n",
       "      <td>8121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>card2</td>\n",
       "      <td>9266</td>\n",
       "      <td>7502</td>\n",
       "      <td>5429</td>\n",
       "      <td>5474</td>\n",
       "      <td>6163</td>\n",
       "      <td>6766.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>addr1</td>\n",
       "      <td>8497</td>\n",
       "      <td>6253</td>\n",
       "      <td>4836</td>\n",
       "      <td>5380</td>\n",
       "      <td>5647</td>\n",
       "      <td>6122.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            index  Fold_1  Fold_2  Fold_3  Fold_4  Fold_5     avg\n",
       "0           card1   12171    9377    7007    7353    8683  8918.2\n",
       "1   TransactionID   11609    9044    6608    6961    7552  8354.8\n",
       "2  TransactionAmt   11495    8869    6180    7030    7031  8121.0\n",
       "3           card2    9266    7502    5429    5474    6163  6766.8\n",
       "4           addr1    8497    6253    4836    5380    5647  6122.6"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance.to_csv('../importances/importances1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3663549</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3663550</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3663551</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3663552</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3663553</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  isFraud\n",
       "0        3663549      0.5\n",
       "1        3663550      0.5\n",
       "2        3663551      0.5\n",
       "3        3663552      0.5\n",
       "4        3663553      0.5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['isFraud'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3663549</td>\n",
       "      <td>0.001240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3663550</td>\n",
       "      <td>0.000725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3663551</td>\n",
       "      <td>0.001453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3663552</td>\n",
       "      <td>0.001341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3663553</td>\n",
       "      <td>0.001067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID   isFraud\n",
       "0        3663549  0.001240\n",
       "1        3663550  0.000725\n",
       "2        3663551  0.001453\n",
       "3        3663552  0.001341\n",
       "4        3663553  0.001067"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv('../predictions/pred1.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
